{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe2c33c0",
   "metadata": {},
   "source": [
    "# LP-IOANet Training Notebook\n",
    "\n",
    "This notebook runs the LP-IOANet training pipeline with research-grade ResearchTracker metrics.\n",
    "\n",
    "## Features\n",
    "- GPU verification and configuration\n",
    "- ResearchTracker metrics monitoring (PSNR, SSIM, MAE)\n",
    "- Real-time training progress\n",
    "- TensorBoard integration\n",
    "- Training utilities and analysis tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdd2514",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de1e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Set up project path\n",
    "project_root = Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f818d45d",
   "metadata": {},
   "source": [
    "## 2. GPU Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6370d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "print(\"=\" * 80)\n",
    "print(\"GPU VERIFICATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✓ CUDA Available: YES\")\n",
    "    print(f\"✓ GPU Count: {torch.cuda.device_count()}\")\n",
    "    print(f\"✓ Current Device: {torch.cuda.current_device()}\")\n",
    "    print(f\"✓ GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"✓ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    \n",
    "    # Reset GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"✓ GPU Memory Cleared\")\n",
    "else:\n",
    "    print(\"✗ CUDA Not Available - Training will run on CPU (very slow!)\")\n",
    "    print(\"  Recommendation: Use NVIDIA GPU for reasonable training time\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nDevice to use: {device}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eb20a2",
   "metadata": {},
   "source": [
    "## 3. Dataset Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13171517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset structure\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATASET VERIFICATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "dataset_root = project_root / \"Dataset\"\n",
    "\n",
    "if dataset_root.exists():\n",
    "    print(f\"✓ Dataset directory found: {dataset_root}\")\n",
    "    \n",
    "    # Check training data\n",
    "    train_dir = dataset_root / \"train\"\n",
    "    train_input = train_dir / \"input\"\n",
    "    train_target = train_dir / \"target\"\n",
    "    \n",
    "    if train_input.exists() and train_target.exists():\n",
    "        train_count = len(list(train_input.glob(\"*.png\"))) or len(list(train_input.glob(\"*.jpg\")))\n",
    "        print(f\"✓ Training set: {train_count} image pairs\")\n",
    "    else:\n",
    "        print(f\"✗ Training data directories not found\")\n",
    "        print(f\"  Expected: {train_input}, {train_target}\")\n",
    "    \n",
    "    # Check test data\n",
    "    test_dir = dataset_root / \"test\"\n",
    "    test_input = test_dir / \"input\"\n",
    "    test_target = test_dir / \"target\"\n",
    "    \n",
    "    if test_input.exists() and test_target.exists():\n",
    "        test_count = len(list(test_input.glob(\"*.png\"))) or len(list(test_input.glob(\"*.jpg\")))\n",
    "        print(f\"✓ Test set: {test_count} image pairs\")\n",
    "    else:\n",
    "        print(f\"✗ Test data directories not found\")\n",
    "        print(f\"  Expected: {test_input}, {test_target}\")\n",
    "else:\n",
    "    print(f\"✗ Dataset directory not found: {dataset_root}\")\n",
    "    print(f\"  Please create the dataset structure:\")\n",
    "    print(f\"  Dataset/\")\n",
    "    print(f\"  ├── train/\")\n",
    "    print(f\"  │   ├── input/\")\n",
    "    print(f\"  │   └── target/\")\n",
    "    print(f\"  └── test/\")\n",
    "    print(f\"      ├── input/\")\n",
    "    print(f\"      └── target/\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd8d577",
   "metadata": {},
   "source": [
    "## 4. Import Training Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0e9672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training modules\n",
    "try:\n",
    "    from src.models import IOANet, LPIOANet, build_model\n",
    "    from src.data import create_dataloaders\n",
    "    from src.losses import ShadowLoss\n",
    "    from src.utils import ResearchTracker\n",
    "    print(\"✓ All training modules imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ Import error: {e}\")\n",
    "    print(\"  Make sure all source files are in place\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0de1e3",
   "metadata": {},
   "source": [
    "## 5. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb7f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Load training configuration\n",
    "config_path = project_root / \"config\" / \"config.yaml\"\n",
    "\n",
    "if config_path.exists():\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    print(\"\\nTraining Configuration:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Stage 1 config\n",
    "    stage1 = config['training']['stage1']\n",
    "    print(f\"\\nStage 1 (IOANet):\")\n",
    "    print(f\"  Epochs: {stage1['epochs']}\")\n",
    "    print(f\"  Batch Size: {stage1['batch_size']}\")\n",
    "    print(f\"  Input Resolution: 192x256\")\n",
    "    print(f\"  Learning Rate: {stage1['learning_rate']}\")\n",
    "    \n",
    "    # Stage 2 config\n",
    "    stage2 = config['training']['stage2']\n",
    "    print(f\"\\nStage 2 (LP-IOANet):\")\n",
    "    print(f\"  Epochs: {stage2['epochs']}\")\n",
    "    print(f\"  Batch Size: {stage2['batch_size']}\")\n",
    "    print(f\"  Input Resolution: 768x1024\")\n",
    "    print(f\"  Learning Rate: {stage2['learning_rate']}\")\n",
    "    \n",
    "    # Loss weights\n",
    "    print(f\"\\nLoss Configuration:\")\n",
    "    print(f\"  Stage 1 L1 Weight: {stage1.get('loss_weights', {}).get('l1', 10.0)}\")\n",
    "    print(f\"  Stage 1 LPIPS Weight: {stage1.get('loss_weights', {}).get('lpips', 5.0)}\")\n",
    "    print(f\"  Stage 2 L1 Weight: {stage2.get('loss_weights', {}).get('l1', 1.0)}\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(f\"✗ Config file not found: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b51502d",
   "metadata": {},
   "source": [
    "## 6. Run Training - Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff22f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training script for Stage 1\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STARTING STAGE 1 TRAINING (IOANet at 192x256)\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nThis will train for 1000 epochs with ResearchTracker metrics.\")\n",
    "print(\"Metrics: PSNR, SSIM, MAE, Loss components\")\n",
    "print(\"\\nPress Ctrl+C to interrupt training\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# Run training\n",
    "result = subprocess.run(\n",
    "    [sys.executable, \"train.py\", \"--stage\", \"1\"],\n",
    "    cwd=project_root,\n",
    "    capture_output=False\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining exit code: {result.returncode}\")\n",
    "if result.returncode == 0:\n",
    "    print(\"✓ Stage 1 training completed successfully\")\n",
    "else:\n",
    "    print(f\"✗ Training failed with exit code {result.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae8ffb6",
   "metadata": {},
   "source": [
    "## 7. Training Monitoring - Real-time Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1605b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor training progress from logs\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "log_dir = project_root / \"logs\"\n",
    "\n",
    "if log_dir.exists():\n",
    "    print(\"\\nTraining Logs Found:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # List recent runs\n",
    "    runs = sorted(log_dir.glob(\"run_*\"), key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "    \n",
    "    if runs:\n",
    "        latest_run = runs[0]\n",
    "        print(f\"Latest run: {latest_run.name}\")\n",
    "        print(f\"\\nTo monitor training with TensorBoard:\")\n",
    "        print(f\"  tensorboard --logdir={log_dir}\")\n",
    "        print(f\"\\nThen open: http://localhost:6006\")\n",
    "        print(\"\\nAvailable metrics:\")\n",
    "        print(\"  - train/psnr, train/ssim, train/mae\")\n",
    "        print(\"  - val/psnr, val/ssim, val/mae\")\n",
    "        print(\"  - train/loss, val/loss\")\n",
    "        print(\"  - train/lr (learning rate)\")\n",
    "    else:\n",
    "        print(\"No training runs found\")\n",
    "else:\n",
    "    print(\"Logs directory not yet created (will be created during training)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffa860c",
   "metadata": {},
   "source": [
    "## 8. Run Training - Stage 2 (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19034476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Stage 2 training (after Stage 1 is complete)\n",
    "# Uncomment to run Stage 2\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STARTING STAGE 2 TRAINING (LP-IOANet at 768x1024)\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n⚠️  Note: Stage 2 should only run after Stage 1 completes successfully\")\n",
    "print(\"    Ensure MAE < 0.05 before proceeding\")\n",
    "print(\"\\nUncomment the code below to start Stage 2 training\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Uncomment to run:\n",
    "# result = subprocess.run(\n",
    "#     [sys.executable, \"train.py\", \"--stage\", \"2\"],\n",
    "#     cwd=project_root,\n",
    "#     capture_output=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34310d5d",
   "metadata": {},
   "source": [
    "## 9. Post-Training Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee8bae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training outputs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\nPost-Training Analysis\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check checkpoints\n",
    "checkpoint_dir = project_root / \"checkpoints\"\n",
    "if checkpoint_dir.exists():\n",
    "    checkpoints = list(checkpoint_dir.glob(\"*.pth\"))\n",
    "    print(f\"✓ Checkpoints saved: {len(checkpoints)} files\")\n",
    "    \n",
    "    if checkpoints:\n",
    "        best_model = checkpoint_dir / \"best_model.pth\"\n",
    "        if best_model.exists():\n",
    "            size_mb = best_model.stat().st_size / (1024 * 1024)\n",
    "            print(f\"✓ Best model saved: {size_mb:.2f} MB\")\n",
    "\n",
    "# Check debug samples\n",
    "debug_dir = project_root / \"debug_samples\"\n",
    "if debug_dir.exists():\n",
    "    samples = list(debug_dir.glob(\"*.png\"))\n",
    "    print(f\"✓ Debug samples saved: {len(samples)} images\")\n",
    "    \n",
    "    if samples:\n",
    "        print(f\"  Latest: {samples[-1].name}\")\n",
    "        print(f\"\\n  View samples in: {debug_dir}\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1c6d80",
   "metadata": {},
   "source": [
    "## 10. Test Metrics on Sample Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e08cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ResearchTracker with sample data\n",
    "print(\"\\nTesting ResearchTracker Metrics\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from src.utils import ResearchTracker\n",
    "\n",
    "# Create test data\n",
    "tracker = ResearchTracker()\n",
    "\n",
    "# Simulate batch\n",
    "torch.manual_seed(42)\n",
    "pred = torch.rand(4, 3, 192, 256)\n",
    "target = torch.rand(4, 3, 192, 256)\n",
    "target = target * 0.7 + pred * 0.3  # Add correlation\n",
    "\n",
    "losses = {\n",
    "    'total': 1.23456,\n",
    "    'l1': 0.12345,\n",
    "    'lpips': 0.08901\n",
    "}\n",
    "\n",
    "tracker.update(pred, target, losses)\n",
    "metrics = tracker.get_avg()\n",
    "\n",
    "print(\"\\nSample Metrics Output:\")\n",
    "print(f\"  MAE:        {metrics['mae']:.5f}\")\n",
    "print(f\"  PSNR:       {metrics['psnr']:.2f} dB\")\n",
    "print(f\"  SSIM:       {metrics['ssim']:.4f}\")\n",
    "print(f\"  Total Loss: {metrics['total']:.5f}\")\n",
    "print(f\"  L1 Loss:    {metrics['l1']:.5f}\")\n",
    "print(f\"  LPIPS Loss: {metrics['lpips']:.5f}\")\n",
    "\n",
    "# Test formatting\n",
    "log = tracker.format_log(0, 1000, stage=\"TRAIN\", lr=1e-3, time_sec=45.3)\n",
    "print(f\"\\nFormatted Log Output:\")\n",
    "print(f\"  {log}\")\n",
    "\n",
    "print(\"\\n✓ ResearchTracker working correctly\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60d1275",
   "metadata": {},
   "source": [
    "## 11. Utilities - Check Training Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e48207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to check training status\n",
    "def check_training_status():\n",
    "    print(\"\\nTraining Status Check\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Check for running processes\n",
    "    result = subprocess.run(\n",
    "        [\"tasklist\", \"/FI\", \"IMAGENAME eq python.exe\"],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    if \"python.exe\" in result.stdout:\n",
    "        print(\"✓ Python process running (training may be active)\")\n",
    "    else:\n",
    "        print(\"✗ No Python process found\")\n",
    "    \n",
    "    # Check GPU\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"✓ GPU Memory Used: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "        print(f\"✓ GPU Memory Cached: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "\n",
    "check_training_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc4240",
   "metadata": {},
   "source": [
    "## 12. Utilities - View Debug Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d209560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display debug samples from training\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "debug_dir = project_root / \"debug_samples\"\n",
    "\n",
    "if debug_dir.exists():\n",
    "    samples = sorted(glob.glob(str(debug_dir / \"*.png\")), reverse=True)\n",
    "    \n",
    "    if samples:\n",
    "        print(f\"\\nFound {len(samples)} debug samples\")\n",
    "        print(f\"Latest 3 samples:\")\n",
    "        \n",
    "        for sample_path in samples[:3]:\n",
    "            print(f\"\\n  {Path(sample_path).name}\")\n",
    "            \n",
    "            # Display image\n",
    "            img = Image.open(sample_path)\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title(Path(sample_path).name)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"No debug samples yet (will be generated during training)\")\n",
    "else:\n",
    "    print(f\"Debug directory not found: {debug_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00844f",
   "metadata": {},
   "source": [
    "## 13. Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89e2c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "╔════════════════════════════════════════════════════════════════════════════════╗\n",
    "║                         TRAINING NEXT STEPS                                    ║\n",
    "╚════════════════════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "1. MONITOR TRAINING PROGRESS\n",
    "   ✓ Run TensorBoard: tensorboard --logdir=logs/\n",
    "   ✓ Open http://localhost:6006 in browser\n",
    "   ✓ Watch PSNR, SSIM, MAE, and loss curves\n",
    "\n",
    "2. STAGE 1 SUCCESS CRITERIA (after ~100 epochs)\n",
    "   ✓ PSNR > 27 dB\n",
    "   ✓ SSIM > 0.78\n",
    "   ✓ MAE < 0.05\n",
    "   ✓ Loss smoothly decreasing\n",
    "\n",
    "3. REVIEW DEBUG SAMPLES\n",
    "   ✓ Check debug_samples/epoch_XXXX_*.png every 5 epochs\n",
    "   ✓ Verify attention masks highlight shadows correctly\n",
    "   ✓ Look for artifacts at shadow boundaries\n",
    "\n",
    "4. START STAGE 2 (After Stage 1 Success)\n",
    "   ✓ Uncomment Stage 2 cell above\n",
    "   ✓ Train at 768x1024 resolution\n",
    "   ✓ Target PSNR > 30 dB\n",
    "\n",
    "5. EVALUATION\n",
    "   ✓ Run: python evaluate.py\n",
    "   ✓ Compare metrics on test set\n",
    "   ✓ Save outputs for visual inspection\n",
    "\n",
    "6. TROUBLESHOOTING\n",
    "   - PSNR stalled: Check attention masks in debug_samples/\n",
    "   - SSIM dropping: Reduce L1 weight in config.yaml\n",
    "   - Training slow: Ensure GPU is being used (check nvidia-smi)\n",
    "   - Out of memory: Reduce batch_size in config.yaml\n",
    "\n",
    "╔════════════════════════════════════════════════════════════════════════════════╗\n",
    "║                    For questions, check RESEARCH_TRACKER_SUMMARY.md            ║\n",
    "╚════════════════════════════════════════════════════════════════════════════════╝\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
